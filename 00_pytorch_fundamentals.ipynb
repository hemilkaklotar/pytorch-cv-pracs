{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhIXLUuHWTiLLjF7dzdAUo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hemilkaklotar/pytorch-cv-pracs/blob/main/00_pytorch_fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 00. Pytorch Fundamentals"
      ],
      "metadata": {
        "id": "--uWWf6H8G_5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXMm3vuo7X12"
      },
      "outputs": [],
      "source": [
        "print(\"Learning Pytorch\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "yiLIh75Z74g0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "id": "Lura8sIo8gqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## introduction to tensors\n",
        "\n",
        "### creating tensors"
      ],
      "metadata": {
        "id": "Ow12dWuHX0N9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#scaler\n",
        "scaler = torch.tensor(7)\n",
        "scaler"
      ],
      "metadata": {
        "id": "d2mPgcsX86JN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler.ndim"
      ],
      "metadata": {
        "id": "FzCCkPJEYPSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get tensor back as python int\n",
        "scaler.item()"
      ],
      "metadata": {
        "id": "uOrWOBezYjV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vector\n",
        "\n",
        "vector = torch.tensor([7,7])\n",
        "vector"
      ],
      "metadata": {
        "id": "Ze-OxcshYmWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector.ndim"
      ],
      "metadata": {
        "id": "JJ_czNxDZEn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector.shape"
      ],
      "metadata": {
        "id": "D1D5hs2QZRQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix\n",
        "MATRIX = torch.tensor([[7,8],\n",
        "                       [9,10]])\n",
        "MATRIX"
      ],
      "metadata": {
        "id": "ebyeLRE0ZWRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MATRIX.ndim"
      ],
      "metadata": {
        "id": "85CWSqRPZowk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MATRIX[1]"
      ],
      "metadata": {
        "id": "8YQpbfW4Z5H_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MATRIX.shape"
      ],
      "metadata": {
        "id": "7XgwGtzxZ6hP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor\n",
        "TENSOR = torch.tensor([[[1,2,3],\n",
        "                          [3,6,9],\n",
        "                           [2,4,5]]])\n",
        "TENSOR"
      ],
      "metadata": {
        "id": "mb1FSwj6aAvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TENSOR.ndim"
      ],
      "metadata": {
        "id": "prL-MtTfaDtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TENSOR.shape"
      ],
      "metadata": {
        "id": "ncnOnjUyacAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Tensors\n",
        "\n",
        "Why random tensors?\n",
        "\n",
        "Random tensors are important because the way many neural networks learn is that they start with tensors full of random nubmers and then adjust those random numbers to better represent the data.\n",
        "\n",
        "Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers\n",
        "\n"
      ],
      "metadata": {
        "id": "PkLRF7MLagDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a random tensor of size (3,4).."
      ],
      "metadata": {
        "id": "m41q6SRTbf-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_tensor = torch.rand(3,4)\n",
        "random_tensor"
      ],
      "metadata": {
        "id": "KgG6x76Ab0si"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_tensor.ndim"
      ],
      "metadata": {
        "id": "iybSh743cEB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a random tensor with similar shape to an image tensor\n",
        "random_image_size_tensor = torch.rand(size=(3,224,224)) # colour channels (R, G, B), height, width\n",
        "random_image_size_tensor.shape, random_image_size_tensor.ndim"
      ],
      "metadata": {
        "id": "-JkpjT7ocMIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zeros and Ones"
      ],
      "metadata": {
        "id": "yHf1kXIvdLcY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor of all zeros\n",
        "zeros = torch.zeros(size=(3,4))\n",
        "zeros"
      ],
      "metadata": {
        "id": "x27O7JzodxAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ones = torch.ones(size=(3,4))\n",
        "ones"
      ],
      "metadata": {
        "id": "OkFH_ULkeNZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ones.dtype"
      ],
      "metadata": {
        "id": "6Iu8-wA0eUpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_tensor.dtype"
      ],
      "metadata": {
        "id": "cL3hfl-wec_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a range of tensors and tensors-like"
      ],
      "metadata": {
        "id": "Q8B74Q9seg4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use torch.range() is deprecated, use torch.arange()\n",
        "one_to_ten = torch.arange(start=0,end=11, step=1)\n",
        "one_to_ten"
      ],
      "metadata": {
        "id": "5vAgYlCzeqDz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating tensors like\n",
        "ten_zeros = torch.zeros_like(input=one_to_ten)\n",
        "ten_zeros"
      ],
      "metadata": {
        "id": "Kn8zK80ce3hS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor datatypes\n",
        "** Note:** Tensor datatypes is one of the 3 big errors you'll run into with PyTorch & deep learning:\n",
        "1. Tensors not right datatype\n",
        "2. Tensors not right shape\n",
        "3. Tensors not on the right device"
      ],
      "metadata": {
        "id": "txQyxBe9fcD_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Float 32 tensor\n",
        "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
        "                                dtype=None, # what datatypes is? like float32 float16\n",
        "                                device=None, # what device is your tensor on\n",
        "                                requires_grad=False) # whetherv or not to track gradients\n",
        "float_32_tensor , float_32_tensor"
      ],
      "metadata": {
        "id": "FbXu9vWRgDgO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "float_32_tensor.dtype"
      ],
      "metadata": {
        "id": "BAzcJXN1gVan"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "float_16_tensor = float_32_tensor.type(torch.float16)\n",
        "float_16_tensor"
      ],
      "metadata": {
        "id": "GJviQCNSw_im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "float_integration = float_16_tensor * float_32_tensor\n",
        "float_integration"
      ],
      "metadata": {
        "id": "4R318KOnxGhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "float_integration.dtype"
      ],
      "metadata": {
        "id": "JqL3nVNsxec6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "int_32_tensor = torch.tensor([3,6,9], dtype=torch.long)\n",
        "int_32_tensor\n"
      ],
      "metadata": {
        "id": "Xt18ulylxoXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "float_32_tensor * int_32_tensor"
      ],
      "metadata": {
        "id": "xMeKmxulyKEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting information from tensor\n",
        "\n",
        "1. Tensor not right datatype - to do get datattype from a tensor, can use `tensor.dtype`\n",
        "2. Tensor not right shape - to get shape from a tensor, can use `tensor.shape`\n",
        "3. Tensors not on the right device - to get device from a tensor, can use `tensor.device`"
      ],
      "metadata": {
        "id": "NjVDhNTCyPDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor\n",
        "some_tensor = torch.rand(3,4)\n",
        "some_tensor"
      ],
      "metadata": {
        "id": "gUPfAOA_ykVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find out details about some tensor\n",
        "print(some_tensor)\n",
        "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
        "print(f\"Shape of tensor: {some_tensor.shape}\") #tenosr.size() is also same result\n",
        "print(f\"Device tensor is on\")"
      ],
      "metadata": {
        "id": "rbqRLqiNynXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Manipulating Tensors (tensor operations)\n",
        "\n",
        "Tensor operations include:\n",
        "* Addition\n",
        "* Subtraction\n",
        "* Multiplication (element wise)\n",
        "* Division\n",
        "* Matrix Multiplication"
      ],
      "metadata": {
        "id": "yz-TafUX0Hzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a tensor\n",
        "tensor_1 = torch.tensor([1,2,3])\n",
        "tensor_1 + 10"
      ],
      "metadata": {
        "id": "6GP1ik1J1Qbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_1 * 10"
      ],
      "metadata": {
        "id": "Ib1c1WDJ1gOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# subtract 10\n",
        "tensor_1 - 10"
      ],
      "metadata": {
        "id": "TmDGedZK1i7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# try out PyTorch in-built functions\n",
        "torch.mul(tensor_1, 10)"
      ],
      "metadata": {
        "id": "r9RV45S-1yF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.add(tensor_1, 100)"
      ],
      "metadata": {
        "id": "TT4juRse19y5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Matrix Multiplication\n",
        "\n",
        "Two main ways of performing multiplication in neural networks and deeplearning\n",
        "\n",
        "1. Element wise multiplicattion\n",
        "2. Matrix multiplication (dot product)\n"
      ],
      "metadata": {
        "id": "UnDAbHXH2HGJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Element wise multiplication\n",
        "print(tensor_1 , \"*\" , tensor_1)\n",
        "print(f\"Equals: {tensor_1 * tensor_1}\")"
      ],
      "metadata": {
        "id": "k3Vctbe_2_t0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix multiplication\n",
        "%%time\n",
        "torch.matmul(tensor_1, tensor_1) # we can use `tenser_1 @ tensor_1` also for matmul"
      ],
      "metadata": {
        "id": "BoxL2e523EBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Matrix multiplication by hand\n",
        "# 1 * 1 +  2 * 2 + 3 * 3\n",
        "\n",
        "%%time\n",
        "value = 0\n",
        "for i in range(len(tensor_1)):\n",
        "  value += tensor_1[i] * tensor_1[i]\n",
        "print(value)"
      ],
      "metadata": {
        "id": "Fdp6QNgD3u-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.matmul(torch.rand(3,10), torch.rand(10,3)).shape"
      ],
      "metadata": {
        "id": "ruTY-xuT4ZF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_A = torch.tensor([[1,2],\n",
        "                         [3,4],\n",
        "                         [5,6]])\n",
        "tensor_B = torch.tensor([[7,10],\n",
        "                         [8,11],\n",
        "                         [9,12]])\n",
        "\n",
        "# torch.mm(tensor_A, tensor_B) is same as matmul\n",
        "# torch.matmul(tensor_A, tensor_B)\n"
      ],
      "metadata": {
        "id": "n8z9u4xo5hXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "to fix our tensor shape issues , we can manipulate the shape of one our tensors using shapes\n",
        "\n",
        "A **transpose** switches the axes of dimenstions of a given tensor"
      ],
      "metadata": {
        "id": "AWGhv4du6zlr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_B.shape"
      ],
      "metadata": {
        "id": "8oS1jw667LKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_B.T.shape, tensor_B.T # .T for transpose"
      ],
      "metadata": {
        "id": "OAI5IVS47GRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  matrix multiplication operations works when tensor_B is transposed\n",
        "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\")\n",
        "print(f\"New Shapes: tensor_A = {tensor_A.shape} (same shape as above), tensor_B.T = {tensor_B.T.shape}\")\n",
        "print(f\"Multplying: {tensor_A.shape} @ {tensor_B.T.shape} <- inner dimensions must match\")\n",
        "print(\"Output:\\n\")\n",
        "output = torch.matmul(tensor_A, tensor_B.T)\n",
        "print(output)\n",
        "print(f\"\\nOutput shape: {output.shape}\")\n"
      ],
      "metadata": {
        "id": "Wdqrj8a77OmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding the min, max, mean, sum, etc (tensor aggregation)"
      ],
      "metadata": {
        "id": "ACZxFlY97yGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor\n",
        "x = torch.arange(1,100,10)\n",
        "x"
      ],
      "metadata": {
        "id": "etLYUtGH9uJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the min\n",
        "torch.min(x), x.min()"
      ],
      "metadata": {
        "id": "sO_k5QyK-Aek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the max\n",
        "torch.max(x), x.max()"
      ],
      "metadata": {
        "id": "phMBEW0k-JrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mean(x.type(torch.float32)), x.type(torch.float32).mean()"
      ],
      "metadata": {
        "id": "l2AgQE9c-OVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sum(x), x.sum()"
      ],
      "metadata": {
        "id": "yGIFjwo9-TWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finding the positional min and max"
      ],
      "metadata": {
        "id": "FEC9jfCW9OMb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "id": "npgt8z5a9gyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the position in tensor that has the minimum value with argmin() -> return index position of target tensor where the minimum value occurs\n",
        "x.argmin()"
      ],
      "metadata": {
        "id": "52y2vZNQ9cns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the position in tensor that has the maximum value with argmax()\n",
        "x.argmax()"
      ],
      "metadata": {
        "id": "KPWl47X49fNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reshaping, stacking, squeezing and unsqueezing tensors\n",
        "\n",
        "* Reshaping - reshapes an input tensor to a defined shape\n",
        "* View - Return a view of an input tensor of certain shape but keep the same memory as the original tensor\n",
        "* Stacking - combine muliple  tensors on top of each otehr (vstack) or side by side (hstack)\n",
        "* Squeeze - removes all `1` dimensions from a tensor\n",
        "* Unsqueeze - add a `1` dimension to a target tensor\n",
        "* Permute - Return a view of the input with dimensions permuted (swapped) in certain way"
      ],
      "metadata": {
        "id": "KRWdhWmw-L1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's create a tensor\n",
        "import torch\n",
        "x = torch.arange(1., 10.)\n",
        "x, x.shape"
      ],
      "metadata": {
        "id": "Wy2_XOtu_yx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add an extra dimension\n",
        "x_reshaped = x.reshape(1,9)\n",
        "x_reshaped, x_reshaped.shape"
      ],
      "metadata": {
        "id": "qe0Bzz5r_4Ss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the view\n",
        "z = x.view(1, 9)\n",
        "z, z.shape"
      ],
      "metadata": {
        "id": "DNhIoE2V_6fN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# changing z changes x (because a view of a tensor shaeres the same memory as the original input)\n",
        "z[:, 0] = 5\n",
        "z, x"
      ],
      "metadata": {
        "id": "8YTAE2G7_6qF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# stack tensors on top of each other\n",
        "x_stacked = torch.stack([x, x, x, x], dim=0)\n",
        "x_stacked"
      ],
      "metadata": {
        "id": "CTpTbDy4CE_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.squeeze() - remove all single dimensions from a target tensor\n",
        "print(f\"Previous tensor: {x_reshaped}\")\n",
        "print(f\"Previous shape: {x_reshaped.shape}\")\n",
        "\n",
        "# Remove extra dimensions from x_reshaped\n",
        "x_squeezed = x_reshaped.squeeze()\n",
        "print(f\"\\nNew tensor: {x_squeezed}\")\n",
        "print(f\"New shape: {x_squeezed.shape}\")"
      ],
      "metadata": {
        "id": "eXBL4n-WEkYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.unsqueeze() - adds a single dimensions to a target tensor at a specific dim (dimensions)\n",
        "print(f\"Previous target: {x_squeezed}\")\n",
        "print(f\"Previous shape: {x_squeezed.shape}\")\n",
        "\n",
        "# Add an extra dimension with unsqueeze\n",
        "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
        "print(f\"\\nNew tensor: {x_unsqueezed}\")\n",
        "print(f\"New shape: {x_unsqueezed.shape}\")"
      ],
      "metadata": {
        "id": "gnnYbdAaGcE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Torch.permute - rearranges the dimensions of target tensor in specified order\n",
        "x_original = torch.rand(size=(224,224,3)) # [height , width, colour_channels]\n",
        "\n",
        "# Permute the original tensor to rearrange the axis (or dim) order\n",
        "x_permute = x_original.permute(2, 0 ,1) # shifts axis 0->1 , 1->2, 2->0\n",
        "\n",
        "print(f\"Previous shape: {x_original.shape}\")\n",
        "print(f\"New shape: {x_permute.shape}\") # [colour_channels, height, width]\n"
      ],
      "metadata": {
        "id": "Eqt4g2lvGeKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_permute[0,0,0]"
      ],
      "metadata": {
        "id": "rZzOjlRUKMmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_original[0,0,0]"
      ],
      "metadata": {
        "id": "UyoQ3btjKk7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_original[0,0,0] = 5775\n",
        "x_permute[0,0,0]"
      ],
      "metadata": {
        "id": "hAXXibKdKqf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Indexing (selecting data from tensors)\n",
        "\n",
        "Indexing with PyTorch is similar to indexing with NumPy"
      ],
      "metadata": {
        "id": "Vrbe391kKywM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a tensor\n",
        "import torch\n",
        "x = torch.arange(1,10).reshape(1,3,3)\n",
        "x, x.shape"
      ],
      "metadata": {
        "id": "YoTgP9N4LNzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's index on our new tensor\n",
        "x[0]"
      ],
      "metadata": {
        "id": "U1DGwyp5LXUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's index on the middle bracket (dim=1)\n",
        "x[0][0]"
      ],
      "metadata": {
        "id": "1UkWBOXqLkMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's index on the most inner bracket (last dimension)\n",
        "x[0][1][1]"
      ],
      "metadata": {
        "id": "50duM05zMesm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You can also use \":\" select \"all\" of a target dimension\n",
        "x[:, 0]"
      ],
      "metadata": {
        "id": "4wGROAYJMrZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all values of 0th and 1st dimensions but only index 1 of 2nd dimensions\n",
        "x[:, :,1]"
      ],
      "metadata": {
        "id": "wkYEoc8TNJS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all values of the 0 dimension but only the 1 index value of 1 st and 2nd dimension\n",
        "x[:, 1, 1]"
      ],
      "metadata": {
        "id": "akLsICIfKSfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get index 0 of oth and 1st dimension and all values of 2nd dimension\n",
        "x[0, 0, :]"
      ],
      "metadata": {
        "id": "-6HHRBkoK7ke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# index on x to return 9\n",
        "x[:, 2, 2]"
      ],
      "metadata": {
        "id": "_KN4DVu1LK54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# index on x to return 3, 6, 9\n",
        "x[:, :, 2]"
      ],
      "metadata": {
        "id": "BOEgSTUjLYTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PyTorch tensors & NumPy\n",
        "\n",
        "Numpy is a popular scientific Python numerical computing library.\n",
        "and because of this, PyTorch has functionality to interact with it.\n",
        "\n",
        "* Data in NumPy,  want in PyTorch tensor -> `torch.from_numpy(ndarray)`\n",
        "* PyTorch tensor -> NumPy -> `tensor.Tensor.numpy()"
      ],
      "metadata": {
        "id": "HChYYULCLjdY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Numpy array to tensor\n",
        "import torch\n",
        "import numpy as np\n",
        "array = np.arange(1.0,8.0)\n",
        "tensor = torch.from_numpy(array) # when converting from numpy -> pytorch data tyep will be float64 need to convert into usable datatype using .type(torch.float32)\n",
        "array, tensor"
      ],
      "metadata": {
        "id": "rJiE-Xs0Mbdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the value of array, what will this do to `tensor`?\n",
        "array = array + 1\n",
        "array, tensor"
      ],
      "metadata": {
        "id": "AmfzxUFTMsT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensor to NumPy array\n",
        "tensor = torch.ones(7)\n",
        "numpy_tensor = tensor.numpy()\n",
        "tensor, numpy_tensor"
      ],
      "metadata": {
        "id": "m60_kAveNf7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the tensor, what happens to `numpy_tensor`?\n",
        "tensor = tensor + 1\n",
        "tensor, numpy_tensor"
      ],
      "metadata": {
        "id": "h84Sx2rIOK4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reproduciblility (trying to take random out of random)\n",
        "\n",
        "In short how a neural network learns:\n",
        "\n",
        "`start with random numbers -> tensor operations -> update random numbers to try and make them of the data -> again -> again -> again...`\n",
        "\n",
        "To reduce the randomness in neural networks and PyTorch comes the concept of a random seed.\n",
        "Essentially what the random seed does is \"flavour\" the randomness."
      ],
      "metadata": {
        "id": "-igbX5MOOXRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Create two random tensors\n",
        "random_tensor_A = torch.rand(3, 4)\n",
        "random_tensor_B = torch.rand(3, 4)\n",
        "\n",
        "print(random_tensor_A)\n",
        "print(random_tensor_B)\n",
        "\n",
        "print(random_tensor_A == random_tensor_B)"
      ],
      "metadata": {
        "id": "OWgsnrh1PLa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's make some random but reproducible tensors\n",
        "import torch\n",
        "\n",
        "# set the random seed\n",
        "RANDOM_SEED = 42\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "random_tensor_C = torch.rand(3, 4)\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "random_tensor_D = torch.rand(3, 4)\n",
        "\n",
        "print(random_tensor_C)\n",
        "print(random_tensor_D)\n",
        "print(random_tensor_C == random_tensor_D)"
      ],
      "metadata": {
        "id": "uVm_UigcPQKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running tensors and PyTorch objects on the GPUs (and making faster computations)\n",
        "\n",
        "GPUs = faster computationan on numbers, thanks to CUDA + NVIDIA hardware + PyTorch working behind the scenes to make everything hunky dory(good)\n"
      ],
      "metadata": {
        "id": "_FC5zRmmQvq4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Getting a GPU\n",
        "\n",
        "1. Easiest - Use Google Colab for a free GPU (options to upgrade as well)\n",
        "2. Use your GPU = takes a bit setup and requires the investment of purchasing\n",
        "3. Use cloud computing - GCP, AWS, Azure these services allow you to rent computers on the cloud and access them"
      ],
      "metadata": {
        "id": "F7ZPcvx4SfPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "Hs0NjWu2TquF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aae826ed-ff2f-4139-a277-28bd69bd6a7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Apr  1 17:33:01 2024       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 551.61                 Driver Version: 551.61         CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                     TCC/WDDM  | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA GeForce GTX 1650      WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
            "| N/A   47C    P8              1W /   50W |       0MiB /   4096MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|    0   N/A  N/A     18896    C+G   ...8bbwe\\SnippingTool\\SnippingTool.exe      N/A      |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU access with Pytorch\n",
        "\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "4FVDwpJCTsCJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f9162e7-c93d-4c67-8c46-cd970bae36b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For PyTorch since it's capable of running compute on the GPU or CPU, it's best practice to setup device agnostic code: https://pytorch.org/docs/stable/notes/cuda.html#best-practices\n",
        "\n",
        "E.g. run on the GPU if available, else default to CPU\n"
      ],
      "metadata": {
        "id": "9oPjQ0OSkqHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "XVojOfiGiLiL",
        "outputId": "18034f25-367e-4650-cbb3-2ed01fd00940"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count number of devices\n",
        "torch.cuda.device_count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Y5R0USYj7zz",
        "outputId": "6e848c0f-720c-400d-9df2-04f1bb4b7dfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Putting tensors (and models) on the GPU\n",
        "\n",
        "The reason we want out tensors/models on the GPU is because using GPU results in faster computations.\n"
      ],
      "metadata": {
        "id": "3LrtW8sukDtq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a tensor (default on the CPU)\n",
        "\n",
        "tensor = torch.tensor([1,2,3])\n",
        "\n",
        "# Tensor not on GPU\n",
        "print (tensor, tensor.device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iS9LnoSilyhb",
        "outputId": "9242bdb4-386c-41ee-b7b0-9fbef01275d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Move tensor to GPU if available regardless is gpu available or not!\n",
        "tensor_on_gpu = tensor.to(device)\n",
        "tensor_on_gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dfoqagx8mDQ8",
        "outputId": "f261c15b-c3dc-4be6-c8ed-2fc48f5bd213"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Moving tensors back to the CPU"
      ],
      "metadata": {
        "id": "ewaSUHxZmV4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If tensor is on GPU, can't transform it to NumPy\n",
        "tensor_on_gpu.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWpde2y_msZj",
        "outputId": "ed230d9b-12d1-459d-f5af-520a7472c1c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To fix the GPU tensor with NumPy issue, we can first set it to the CPU\n",
        "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
        "tensor_back_on_cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSBcpTg4m2tR",
        "outputId": "60ffc5b6-8ceb-4ad8-cbff-af326383149a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_on_gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njLWBNwfnMj1",
        "outputId": "0f75b67b-ac10-4320-f451-29fbfbf3a43e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}